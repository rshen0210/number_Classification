{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "109a8dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b0809b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train = True,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train = False,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b7dd38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5296b14e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19e26330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc5c9862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4be21be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d0dccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "    'train': DataLoader(train_data,\n",
    "                        batch_size=100,\n",
    "                        shuffle=True,\n",
    "                        num_workers=1),\n",
    "    'test': DataLoader(test_data,\n",
    "                        batch_size=100,\n",
    "                        shuffle=True,\n",
    "                        num_workers=1),\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eed9df09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x16e3e7c50>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x16e3e6180>}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f9bbee96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,10,kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10,20,kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return F.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6802d9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) \n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders[\"train\"].dataset)} ({100. * batch_idx / len(loaders[\"train\"]):.0f}%)]\\t{loss.item():.6f}')\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders['test']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(loaders['test'].dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy {correct}/{len(loaders[\"test\"].dataset)} ({100. * correct / len(loaders[\"test\"].dataset):.0f}%\\n)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fc8259f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gt/bgj3wwr17sj551f00_bg8t7m0000gp/T/ipykernel_2280/2141946115.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\t2.303212\n",
      "Train Epoch: 1 [2000/60000 (3%)]\t2.274812\n",
      "Train Epoch: 1 [4000/60000 (7%)]\t2.025963\n",
      "Train Epoch: 1 [6000/60000 (10%)]\t1.969023\n",
      "Train Epoch: 1 [8000/60000 (13%)]\t1.947217\n",
      "Train Epoch: 1 [10000/60000 (17%)]\t1.864405\n",
      "Train Epoch: 1 [12000/60000 (20%)]\t1.880456\n",
      "Train Epoch: 1 [14000/60000 (23%)]\t1.829210\n",
      "Train Epoch: 1 [16000/60000 (27%)]\t1.751993\n",
      "Train Epoch: 1 [18000/60000 (30%)]\t1.679814\n",
      "Train Epoch: 1 [20000/60000 (33%)]\t1.725451\n",
      "Train Epoch: 1 [22000/60000 (37%)]\t1.630023\n",
      "Train Epoch: 1 [24000/60000 (40%)]\t1.714171\n",
      "Train Epoch: 1 [26000/60000 (43%)]\t1.646071\n",
      "Train Epoch: 1 [28000/60000 (47%)]\t1.701271\n",
      "Train Epoch: 1 [30000/60000 (50%)]\t1.669047\n",
      "Train Epoch: 1 [32000/60000 (53%)]\t1.636299\n",
      "Train Epoch: 1 [34000/60000 (57%)]\t1.685365\n",
      "Train Epoch: 1 [36000/60000 (60%)]\t1.615432\n",
      "Train Epoch: 1 [38000/60000 (63%)]\t1.645405\n",
      "Train Epoch: 1 [40000/60000 (67%)]\t1.614987\n",
      "Train Epoch: 1 [42000/60000 (70%)]\t1.629580\n",
      "Train Epoch: 1 [44000/60000 (73%)]\t1.621632\n",
      "Train Epoch: 1 [46000/60000 (77%)]\t1.634820\n",
      "Train Epoch: 1 [48000/60000 (80%)]\t1.634984\n",
      "Train Epoch: 1 [50000/60000 (83%)]\t1.620284\n",
      "Train Epoch: 1 [52000/60000 (87%)]\t1.619032\n",
      "Train Epoch: 1 [54000/60000 (90%)]\t1.578943\n",
      "Train Epoch: 1 [56000/60000 (93%)]\t1.624154\n",
      "Train Epoch: 1 [58000/60000 (97%)]\t1.558461\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy 9348/10000 (93%\n",
      ")\n",
      "Train Epoch: 2 [0/60000 (0%)]\t1.585424\n",
      "Train Epoch: 2 [2000/60000 (3%)]\t1.576372\n",
      "Train Epoch: 2 [4000/60000 (7%)]\t1.649943\n",
      "Train Epoch: 2 [6000/60000 (10%)]\t1.573719\n",
      "Train Epoch: 2 [8000/60000 (13%)]\t1.639279\n",
      "Train Epoch: 2 [10000/60000 (17%)]\t1.533668\n",
      "Train Epoch: 2 [12000/60000 (20%)]\t1.620132\n",
      "Train Epoch: 2 [14000/60000 (23%)]\t1.590610\n",
      "Train Epoch: 2 [16000/60000 (27%)]\t1.614062\n",
      "Train Epoch: 2 [18000/60000 (30%)]\t1.529646\n",
      "Train Epoch: 2 [20000/60000 (33%)]\t1.593639\n",
      "Train Epoch: 2 [22000/60000 (37%)]\t1.586782\n",
      "Train Epoch: 2 [24000/60000 (40%)]\t1.639402\n",
      "Train Epoch: 2 [26000/60000 (43%)]\t1.616860\n",
      "Train Epoch: 2 [28000/60000 (47%)]\t1.544215\n",
      "Train Epoch: 2 [30000/60000 (50%)]\t1.562583\n",
      "Train Epoch: 2 [32000/60000 (53%)]\t1.595747\n",
      "Train Epoch: 2 [34000/60000 (57%)]\t1.597065\n",
      "Train Epoch: 2 [36000/60000 (60%)]\t1.573582\n",
      "Train Epoch: 2 [38000/60000 (63%)]\t1.577433\n",
      "Train Epoch: 2 [40000/60000 (67%)]\t1.574872\n",
      "Train Epoch: 2 [42000/60000 (70%)]\t1.578015\n",
      "Train Epoch: 2 [44000/60000 (73%)]\t1.580804\n",
      "Train Epoch: 2 [46000/60000 (77%)]\t1.597033\n",
      "Train Epoch: 2 [48000/60000 (80%)]\t1.527299\n",
      "Train Epoch: 2 [50000/60000 (83%)]\t1.543017\n",
      "Train Epoch: 2 [52000/60000 (87%)]\t1.587118\n",
      "Train Epoch: 2 [54000/60000 (90%)]\t1.594489\n",
      "Train Epoch: 2 [56000/60000 (93%)]\t1.570650\n",
      "Train Epoch: 2 [58000/60000 (97%)]\t1.599428\n",
      "\n",
      "Test set: Average loss: 0.0151, Accuracy 9512/10000 (95%\n",
      ")\n",
      "Train Epoch: 3 [0/60000 (0%)]\t1.569791\n",
      "Train Epoch: 3 [2000/60000 (3%)]\t1.583745\n",
      "Train Epoch: 3 [4000/60000 (7%)]\t1.551589\n",
      "Train Epoch: 3 [6000/60000 (10%)]\t1.582553\n",
      "Train Epoch: 3 [8000/60000 (13%)]\t1.544573\n",
      "Train Epoch: 3 [10000/60000 (17%)]\t1.546655\n",
      "Train Epoch: 3 [12000/60000 (20%)]\t1.562791\n",
      "Train Epoch: 3 [14000/60000 (23%)]\t1.590073\n",
      "Train Epoch: 3 [16000/60000 (27%)]\t1.532664\n",
      "Train Epoch: 3 [18000/60000 (30%)]\t1.573530\n",
      "Train Epoch: 3 [20000/60000 (33%)]\t1.540755\n",
      "Train Epoch: 3 [22000/60000 (37%)]\t1.536295\n",
      "Train Epoch: 3 [24000/60000 (40%)]\t1.575175\n",
      "Train Epoch: 3 [26000/60000 (43%)]\t1.530121\n",
      "Train Epoch: 3 [28000/60000 (47%)]\t1.541556\n",
      "Train Epoch: 3 [30000/60000 (50%)]\t1.562711\n",
      "Train Epoch: 3 [32000/60000 (53%)]\t1.559933\n",
      "Train Epoch: 3 [34000/60000 (57%)]\t1.577878\n",
      "Train Epoch: 3 [36000/60000 (60%)]\t1.547390\n",
      "Train Epoch: 3 [38000/60000 (63%)]\t1.576259\n",
      "Train Epoch: 3 [40000/60000 (67%)]\t1.574374\n",
      "Train Epoch: 3 [42000/60000 (70%)]\t1.572768\n",
      "Train Epoch: 3 [44000/60000 (73%)]\t1.582327\n",
      "Train Epoch: 3 [46000/60000 (77%)]\t1.544789\n",
      "Train Epoch: 3 [48000/60000 (80%)]\t1.566159\n",
      "Train Epoch: 3 [50000/60000 (83%)]\t1.507551\n",
      "Train Epoch: 3 [52000/60000 (87%)]\t1.569636\n",
      "Train Epoch: 3 [54000/60000 (90%)]\t1.574782\n",
      "Train Epoch: 3 [56000/60000 (93%)]\t1.551881\n",
      "Train Epoch: 3 [58000/60000 (97%)]\t1.510944\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy 9580/10000 (96%\n",
      ")\n",
      "Train Epoch: 4 [0/60000 (0%)]\t1.509575\n",
      "Train Epoch: 4 [2000/60000 (3%)]\t1.520412\n",
      "Train Epoch: 4 [4000/60000 (7%)]\t1.536315\n",
      "Train Epoch: 4 [6000/60000 (10%)]\t1.522183\n",
      "Train Epoch: 4 [8000/60000 (13%)]\t1.576959\n",
      "Train Epoch: 4 [10000/60000 (17%)]\t1.612006\n",
      "Train Epoch: 4 [12000/60000 (20%)]\t1.557750\n",
      "Train Epoch: 4 [14000/60000 (23%)]\t1.542939\n",
      "Train Epoch: 4 [16000/60000 (27%)]\t1.514153\n",
      "Train Epoch: 4 [18000/60000 (30%)]\t1.536845\n",
      "Train Epoch: 4 [20000/60000 (33%)]\t1.541602\n",
      "Train Epoch: 4 [22000/60000 (37%)]\t1.505920\n",
      "Train Epoch: 4 [24000/60000 (40%)]\t1.516691\n",
      "Train Epoch: 4 [26000/60000 (43%)]\t1.558854\n",
      "Train Epoch: 4 [28000/60000 (47%)]\t1.535181\n",
      "Train Epoch: 4 [30000/60000 (50%)]\t1.529807\n",
      "Train Epoch: 4 [32000/60000 (53%)]\t1.586145\n",
      "Train Epoch: 4 [34000/60000 (57%)]\t1.542905\n",
      "Train Epoch: 4 [36000/60000 (60%)]\t1.601363\n",
      "Train Epoch: 4 [38000/60000 (63%)]\t1.540106\n",
      "Train Epoch: 4 [40000/60000 (67%)]\t1.550434\n",
      "Train Epoch: 4 [42000/60000 (70%)]\t1.499981\n",
      "Train Epoch: 4 [44000/60000 (73%)]\t1.581399\n",
      "Train Epoch: 4 [46000/60000 (77%)]\t1.530356\n",
      "Train Epoch: 4 [48000/60000 (80%)]\t1.516247\n",
      "Train Epoch: 4 [50000/60000 (83%)]\t1.535124\n",
      "Train Epoch: 4 [52000/60000 (87%)]\t1.522849\n",
      "Train Epoch: 4 [54000/60000 (90%)]\t1.556855\n",
      "Train Epoch: 4 [56000/60000 (93%)]\t1.557558\n",
      "Train Epoch: 4 [58000/60000 (97%)]\t1.530745\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy 9626/10000 (96%\n",
      ")\n",
      "Train Epoch: 5 [0/60000 (0%)]\t1.554667\n",
      "Train Epoch: 5 [2000/60000 (3%)]\t1.499081\n",
      "Train Epoch: 5 [4000/60000 (7%)]\t1.553815\n",
      "Train Epoch: 5 [6000/60000 (10%)]\t1.528024\n",
      "Train Epoch: 5 [8000/60000 (13%)]\t1.543584\n",
      "Train Epoch: 5 [10000/60000 (17%)]\t1.544754\n",
      "Train Epoch: 5 [12000/60000 (20%)]\t1.531183\n",
      "Train Epoch: 5 [14000/60000 (23%)]\t1.549478\n",
      "Train Epoch: 5 [16000/60000 (27%)]\t1.554259\n",
      "Train Epoch: 5 [18000/60000 (30%)]\t1.533012\n",
      "Train Epoch: 5 [20000/60000 (33%)]\t1.527424\n",
      "Train Epoch: 5 [22000/60000 (37%)]\t1.558208\n",
      "Train Epoch: 5 [24000/60000 (40%)]\t1.590453\n",
      "Train Epoch: 5 [26000/60000 (43%)]\t1.514009\n",
      "Train Epoch: 5 [28000/60000 (47%)]\t1.516291\n",
      "Train Epoch: 5 [30000/60000 (50%)]\t1.527160\n",
      "Train Epoch: 5 [32000/60000 (53%)]\t1.556776\n",
      "Train Epoch: 5 [34000/60000 (57%)]\t1.516199\n",
      "Train Epoch: 5 [36000/60000 (60%)]\t1.523538\n",
      "Train Epoch: 5 [38000/60000 (63%)]\t1.529486\n",
      "Train Epoch: 5 [40000/60000 (67%)]\t1.590505\n",
      "Train Epoch: 5 [42000/60000 (70%)]\t1.613364\n",
      "Train Epoch: 5 [44000/60000 (73%)]\t1.511358\n",
      "Train Epoch: 5 [46000/60000 (77%)]\t1.519035\n",
      "Train Epoch: 5 [48000/60000 (80%)]\t1.517553\n",
      "Train Epoch: 5 [50000/60000 (83%)]\t1.575103\n",
      "Train Epoch: 5 [52000/60000 (87%)]\t1.535302\n",
      "Train Epoch: 5 [54000/60000 (90%)]\t1.583524\n",
      "Train Epoch: 5 [56000/60000 (93%)]\t1.564025\n",
      "Train Epoch: 5 [58000/60000 (97%)]\t1.560902\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy 9669/10000 (97%\n",
      ")\n",
      "Train Epoch: 6 [0/60000 (0%)]\t1.532734\n",
      "Train Epoch: 6 [2000/60000 (3%)]\t1.518052\n",
      "Train Epoch: 6 [4000/60000 (7%)]\t1.526291\n",
      "Train Epoch: 6 [6000/60000 (10%)]\t1.521725\n",
      "Train Epoch: 6 [8000/60000 (13%)]\t1.550631\n",
      "Train Epoch: 6 [10000/60000 (17%)]\t1.510804\n",
      "Train Epoch: 6 [12000/60000 (20%)]\t1.506274\n",
      "Train Epoch: 6 [14000/60000 (23%)]\t1.534853\n",
      "Train Epoch: 6 [16000/60000 (27%)]\t1.479430\n",
      "Train Epoch: 6 [18000/60000 (30%)]\t1.529442\n",
      "Train Epoch: 6 [20000/60000 (33%)]\t1.547322\n",
      "Train Epoch: 6 [22000/60000 (37%)]\t1.566163\n",
      "Train Epoch: 6 [24000/60000 (40%)]\t1.565427\n",
      "Train Epoch: 6 [26000/60000 (43%)]\t1.591628\n",
      "Train Epoch: 6 [28000/60000 (47%)]\t1.550817\n",
      "Train Epoch: 6 [30000/60000 (50%)]\t1.520582\n",
      "Train Epoch: 6 [32000/60000 (53%)]\t1.525829\n",
      "Train Epoch: 6 [34000/60000 (57%)]\t1.535426\n",
      "Train Epoch: 6 [36000/60000 (60%)]\t1.529837\n",
      "Train Epoch: 6 [38000/60000 (63%)]\t1.540554\n",
      "Train Epoch: 6 [40000/60000 (67%)]\t1.520678\n",
      "Train Epoch: 6 [42000/60000 (70%)]\t1.529763\n",
      "Train Epoch: 6 [44000/60000 (73%)]\t1.565919\n",
      "Train Epoch: 6 [46000/60000 (77%)]\t1.518058\n",
      "Train Epoch: 6 [48000/60000 (80%)]\t1.500160\n",
      "Train Epoch: 6 [50000/60000 (83%)]\t1.536899\n",
      "Train Epoch: 6 [52000/60000 (87%)]\t1.529075\n",
      "Train Epoch: 6 [54000/60000 (90%)]\t1.499888\n",
      "Train Epoch: 6 [56000/60000 (93%)]\t1.542435\n",
      "Train Epoch: 6 [58000/60000 (97%)]\t1.523513\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy 9693/10000 (97%\n",
      ")\n",
      "Train Epoch: 7 [0/60000 (0%)]\t1.548636\n",
      "Train Epoch: 7 [2000/60000 (3%)]\t1.552761\n",
      "Train Epoch: 7 [4000/60000 (7%)]\t1.516043\n",
      "Train Epoch: 7 [6000/60000 (10%)]\t1.535463\n",
      "Train Epoch: 7 [8000/60000 (13%)]\t1.590945\n",
      "Train Epoch: 7 [10000/60000 (17%)]\t1.517244\n",
      "Train Epoch: 7 [12000/60000 (20%)]\t1.526553\n",
      "Train Epoch: 7 [14000/60000 (23%)]\t1.544106\n",
      "Train Epoch: 7 [16000/60000 (27%)]\t1.524938\n",
      "Train Epoch: 7 [18000/60000 (30%)]\t1.505967\n",
      "Train Epoch: 7 [20000/60000 (33%)]\t1.540052\n",
      "Train Epoch: 7 [22000/60000 (37%)]\t1.533441\n",
      "Train Epoch: 7 [24000/60000 (40%)]\t1.493465\n",
      "Train Epoch: 7 [26000/60000 (43%)]\t1.550751\n",
      "Train Epoch: 7 [28000/60000 (47%)]\t1.512613\n",
      "Train Epoch: 7 [30000/60000 (50%)]\t1.500133\n",
      "Train Epoch: 7 [32000/60000 (53%)]\t1.562127\n",
      "Train Epoch: 7 [34000/60000 (57%)]\t1.510819\n",
      "Train Epoch: 7 [36000/60000 (60%)]\t1.571537\n",
      "Train Epoch: 7 [38000/60000 (63%)]\t1.521464\n",
      "Train Epoch: 7 [40000/60000 (67%)]\t1.553400\n",
      "Train Epoch: 7 [42000/60000 (70%)]\t1.509249\n",
      "Train Epoch: 7 [44000/60000 (73%)]\t1.580035\n",
      "Train Epoch: 7 [46000/60000 (77%)]\t1.492297\n",
      "Train Epoch: 7 [48000/60000 (80%)]\t1.552890\n",
      "Train Epoch: 7 [50000/60000 (83%)]\t1.484074\n",
      "Train Epoch: 7 [52000/60000 (87%)]\t1.538803\n",
      "Train Epoch: 7 [54000/60000 (90%)]\t1.539897\n",
      "Train Epoch: 7 [56000/60000 (93%)]\t1.537484\n",
      "Train Epoch: 7 [58000/60000 (97%)]\t1.571028\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy 9709/10000 (97%\n",
      ")\n",
      "Train Epoch: 8 [0/60000 (0%)]\t1.505643\n",
      "Train Epoch: 8 [2000/60000 (3%)]\t1.555834\n",
      "Train Epoch: 8 [4000/60000 (7%)]\t1.542080\n",
      "Train Epoch: 8 [6000/60000 (10%)]\t1.520548\n",
      "Train Epoch: 8 [8000/60000 (13%)]\t1.537349\n",
      "Train Epoch: 8 [10000/60000 (17%)]\t1.543688\n",
      "Train Epoch: 8 [12000/60000 (20%)]\t1.519848\n",
      "Train Epoch: 8 [14000/60000 (23%)]\t1.542602\n",
      "Train Epoch: 8 [16000/60000 (27%)]\t1.577776\n",
      "Train Epoch: 8 [18000/60000 (30%)]\t1.540432\n",
      "Train Epoch: 8 [20000/60000 (33%)]\t1.496706\n",
      "Train Epoch: 8 [22000/60000 (37%)]\t1.517416\n",
      "Train Epoch: 8 [24000/60000 (40%)]\t1.518713\n",
      "Train Epoch: 8 [26000/60000 (43%)]\t1.520973\n",
      "Train Epoch: 8 [28000/60000 (47%)]\t1.529896\n",
      "Train Epoch: 8 [30000/60000 (50%)]\t1.544109\n",
      "Train Epoch: 8 [32000/60000 (53%)]\t1.515499\n",
      "Train Epoch: 8 [34000/60000 (57%)]\t1.539398\n",
      "Train Epoch: 8 [36000/60000 (60%)]\t1.504540\n",
      "Train Epoch: 8 [38000/60000 (63%)]\t1.523281\n",
      "Train Epoch: 8 [40000/60000 (67%)]\t1.556002\n",
      "Train Epoch: 8 [42000/60000 (70%)]\t1.540757\n",
      "Train Epoch: 8 [44000/60000 (73%)]\t1.497359\n",
      "Train Epoch: 8 [46000/60000 (77%)]\t1.532246\n",
      "Train Epoch: 8 [48000/60000 (80%)]\t1.509888\n",
      "Train Epoch: 8 [50000/60000 (83%)]\t1.502477\n",
      "Train Epoch: 8 [52000/60000 (87%)]\t1.549969\n",
      "Train Epoch: 8 [54000/60000 (90%)]\t1.542400\n",
      "Train Epoch: 8 [56000/60000 (93%)]\t1.521533\n",
      "Train Epoch: 8 [58000/60000 (97%)]\t1.515698\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy 9726/10000 (97%\n",
      ")\n",
      "Train Epoch: 9 [0/60000 (0%)]\t1.485089\n",
      "Train Epoch: 9 [2000/60000 (3%)]\t1.576399\n",
      "Train Epoch: 9 [4000/60000 (7%)]\t1.530499\n",
      "Train Epoch: 9 [6000/60000 (10%)]\t1.493951\n",
      "Train Epoch: 9 [8000/60000 (13%)]\t1.524634\n",
      "Train Epoch: 9 [10000/60000 (17%)]\t1.504806\n",
      "Train Epoch: 9 [12000/60000 (20%)]\t1.555174\n",
      "Train Epoch: 9 [14000/60000 (23%)]\t1.498510\n",
      "Train Epoch: 9 [16000/60000 (27%)]\t1.532878\n",
      "Train Epoch: 9 [18000/60000 (30%)]\t1.516081\n",
      "Train Epoch: 9 [20000/60000 (33%)]\t1.556658\n",
      "Train Epoch: 9 [22000/60000 (37%)]\t1.505819\n",
      "Train Epoch: 9 [24000/60000 (40%)]\t1.546293\n",
      "Train Epoch: 9 [26000/60000 (43%)]\t1.526239\n",
      "Train Epoch: 9 [28000/60000 (47%)]\t1.542788\n",
      "Train Epoch: 9 [30000/60000 (50%)]\t1.521755\n",
      "Train Epoch: 9 [32000/60000 (53%)]\t1.542750\n",
      "Train Epoch: 9 [34000/60000 (57%)]\t1.520972\n",
      "Train Epoch: 9 [36000/60000 (60%)]\t1.539898\n",
      "Train Epoch: 9 [38000/60000 (63%)]\t1.549752\n",
      "Train Epoch: 9 [40000/60000 (67%)]\t1.544371\n",
      "Train Epoch: 9 [42000/60000 (70%)]\t1.525602\n",
      "Train Epoch: 9 [44000/60000 (73%)]\t1.529415\n",
      "Train Epoch: 9 [46000/60000 (77%)]\t1.589198\n",
      "Train Epoch: 9 [48000/60000 (80%)]\t1.535861\n",
      "Train Epoch: 9 [50000/60000 (83%)]\t1.491292\n",
      "Train Epoch: 9 [52000/60000 (87%)]\t1.576647\n",
      "Train Epoch: 9 [54000/60000 (90%)]\t1.565345\n",
      "Train Epoch: 9 [56000/60000 (93%)]\t1.510567\n",
      "Train Epoch: 9 [58000/60000 (97%)]\t1.519292\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy 9726/10000 (97%\n",
      ")\n",
      "Train Epoch: 10 [0/60000 (0%)]\t1.528499\n",
      "Train Epoch: 10 [2000/60000 (3%)]\t1.545074\n",
      "Train Epoch: 10 [4000/60000 (7%)]\t1.535498\n",
      "Train Epoch: 10 [6000/60000 (10%)]\t1.532445\n",
      "Train Epoch: 10 [8000/60000 (13%)]\t1.517481\n",
      "Train Epoch: 10 [10000/60000 (17%)]\t1.500372\n",
      "Train Epoch: 10 [12000/60000 (20%)]\t1.547477\n",
      "Train Epoch: 10 [14000/60000 (23%)]\t1.484532\n",
      "Train Epoch: 10 [16000/60000 (27%)]\t1.511909\n",
      "Train Epoch: 10 [18000/60000 (30%)]\t1.552549\n",
      "Train Epoch: 10 [20000/60000 (33%)]\t1.537083\n",
      "Train Epoch: 10 [22000/60000 (37%)]\t1.528429\n",
      "Train Epoch: 10 [24000/60000 (40%)]\t1.540636\n",
      "Train Epoch: 10 [26000/60000 (43%)]\t1.527259\n",
      "Train Epoch: 10 [28000/60000 (47%)]\t1.546152\n",
      "Train Epoch: 10 [30000/60000 (50%)]\t1.519641\n",
      "Train Epoch: 10 [32000/60000 (53%)]\t1.526515\n",
      "Train Epoch: 10 [34000/60000 (57%)]\t1.507933\n",
      "Train Epoch: 10 [36000/60000 (60%)]\t1.507161\n",
      "Train Epoch: 10 [38000/60000 (63%)]\t1.533947\n",
      "Train Epoch: 10 [40000/60000 (67%)]\t1.527320\n",
      "Train Epoch: 10 [42000/60000 (70%)]\t1.564557\n",
      "Train Epoch: 10 [44000/60000 (73%)]\t1.555773\n",
      "Train Epoch: 10 [46000/60000 (77%)]\t1.507550\n",
      "Train Epoch: 10 [48000/60000 (80%)]\t1.540598\n",
      "Train Epoch: 10 [50000/60000 (83%)]\t1.483409\n",
      "Train Epoch: 10 [52000/60000 (87%)]\t1.577205\n",
      "Train Epoch: 10 [54000/60000 (90%)]\t1.497164\n",
      "Train Epoch: 10 [56000/60000 (93%)]\t1.482264\n",
      "Train Epoch: 10 [58000/60000 (97%)]\t1.498623\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy 9748/10000 (97%\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,11):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "61b54cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b0caedc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gt/bgj3wwr17sj551f00_bg8t7m0000gp/T/ipykernel_2280/2141946115.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "\n",
    "data, target = test_data[9095]\n",
    "\n",
    "data = data.unsqueeze(0).to(device)\n",
    "\n",
    "output = model(data)\n",
    "\n",
    "prediction = output.argmax(dim=1, keepdim=True).item()\n",
    "\n",
    "print(f'Prediction: {prediction}')\n",
    "\n",
    "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb56493",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
